{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwdY_vcECrlP",
        "outputId": "c712b683-eda2-4319-91c5-dc8d27391fbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  openjdk-11-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-11-demo openjdk-11-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  | fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-11-jdk-headless openjdk-11-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 57 not upgraded.\n",
            "Need to get 116 MB of archives.\n",
            "After this operation, 258 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre-headless amd64 11.0.29+7-1ubuntu1~22.04 [42.6 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk-headless amd64 11.0.29+7-1ubuntu1~22.04 [73.6 MB]\n",
            "Fetched 116 MB in 4s (31.9 MB/s)\n",
            "Selecting previously unselected package openjdk-11-jre-headless:amd64.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-11-jre-headless_11.0.29+7-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jre-headless:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-11-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-11-jdk-headless_11.0.29+7-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jdk-headless:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "Setting up openjdk-11-jre-headless:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
            "Setting up openjdk-11-jdk-headless:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jaotc to provide /usr/bin/jaotc (jaotc) in auto mode\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------\n",
        "#  Setup Spark in Colab\n",
        "!apt-get update -qq\n",
        "!apt-get install -y openjdk-11-jdk-headless\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar -xf spark-3.5.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark pyspark\n",
        "\n",
        "import os\n",
        "import findspark\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\"\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"CropYieldPrediction\") \\\n",
        "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ï¸âƒ£ Load Data\n",
        "df_spark = spark.read.csv(\"crop_model_data_with_header.csv\", header=True, inferSchema=True)\n",
        "df_spark.show(5)\n",
        "df_spark.printSchema()\n",
        "\n",
        "# ----------------------------\n",
        "# 2ï¸âƒ£ Drop previous index/vec columns if re-running\n",
        "for col_name in [\"crop_index\", \"season_index\", \"state_index\", \"crop_vec\", \"season_vec\", \"state_vec\"]:\n",
        "    if col_name in df_spark.columns:\n",
        "        df_spark = df_spark.drop(col_name)\n",
        "\n",
        "# ----------------------------\n",
        "# 3ï¸âƒ£ Optional: Remove extreme outliers\n",
        "# Filter yields > 100 (adjust threshold if needed)\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Remove extreme outliers\n",
        "df_spark = df_spark.filter(col(\"yield\") <= 100)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 4ï¸âƒ£ Categorical columns\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "categorical_cols = [\"crop\", \"season\", \"state\"]\n",
        "\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\", handleInvalid=\"keep\") for col in categorical_cols]\n",
        "encoders = [OneHotEncoder(inputCol=col+\"_index\", outputCol=col+\"_vec\") for col in categorical_cols]\n",
        "\n",
        "# ----------------------------\n",
        "# 5ï¸âƒ£ Feature Engineering\n",
        "from pyspark.sql.functions import col, log1p, expm1\n",
        "\n",
        "# Log-transform target\n",
        "df_spark = df_spark.withColumn(\"yield_log\", log1p(\"yield\"))\n",
        "\n",
        "# Engineered features\n",
        "df_spark = df_spark.withColumn(\"yield_per_area\", col(\"production\") / col(\"area\"))\n",
        "df_spark = df_spark.withColumn(\"humidity_temp_ratio\", col(\"avg_humidity_percent\") / col(\"avg_temp_c\"))\n",
        "df_spark = df_spark.withColumn(\"rainfall_ph_interaction\", col(\"total_rainfall_mm\") * col(\"ph\"))\n",
        "\n",
        "# ----------------------------\n",
        "# 6ï¸âƒ£ Feature Columns\n",
        "feature_cols = [\n",
        "    \"year\", \"area\", \"production\", \"fertilizer\", \"pesticide\",\n",
        "    \"nitrogen\", \"phosphorus\", \"potassium\", \"ph\",\n",
        "    \"avg_temp_c\", \"total_rainfall_mm\", \"avg_humidity_percent\",\n",
        "    \"yield_per_area\", \"humidity_temp_ratio\", \"rainfall_ph_interaction\",\n",
        "    \"crop_vec\", \"season_vec\", \"state_vec\"\n",
        "]\n",
        "\n",
        "# ----------------------------\n",
        "# 7ï¸âƒ£ Vector Assembler\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "\n",
        "# ----------------------------\n",
        "# 8ï¸âƒ£ Feature Scaling\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
        "\n",
        "# ----------------------------\n",
        "# 9ï¸âƒ£ Full Pipeline (indexing + encoding + assembler + scaling)\n",
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler])\n",
        "df_spark = pipeline.fit(df_spark).transform(df_spark)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-_jZ6ejDayd",
        "outputId": "03415d40-e486-4399-f51d-678b9cfcfc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----+-----------+-----+-------+----------+----------+---------+-----------+--------+----------+---------+---+----------+-----------------+--------------------+\n",
            "|        crop|year|     season|state|   area|production|fertilizer|pesticide|      yield|nitrogen|phosphorus|potassium| ph|avg_temp_c|total_rainfall_mm|avg_humidity_percent|\n",
            "+------------+----+-----------+-----+-------+----------+----------+---------+-----------+--------+----------+---------+---+----------+-----------------+--------------------+\n",
            "|    Arecanut|1997|Whole Year |Assam|73814.0|   56708.0|7024878.38| 22882.34|0.796086957|    60.0|      18.0|     38.0|5.8|     22.41|          1468.92|               70.71|\n",
            "|   Arhar/Tur|1997|Kharif     |Assam| 6637.0|    4685.0| 631643.29|  2057.47|0.710434783|    60.0|      18.0|     38.0|5.8|     22.41|          1468.92|               70.71|\n",
            "| Castor seed|1997|Kharif     |Assam|  796.0|      22.0|  75755.32|   246.76|0.238333333|    60.0|      18.0|     38.0|5.8|     22.41|          1468.92|               70.71|\n",
            "|    Coconut |1997|Whole Year |Assam|19656.0| 1.26905E8|1870661.52|  6093.36|5238.051739|    60.0|      18.0|     38.0|5.8|     22.41|          1468.92|               70.71|\n",
            "|Cotton(lint)|1997|Kharif     |Assam| 1739.0|     794.0| 165500.63|   539.09|0.420909091|    60.0|      18.0|     38.0|5.8|     22.41|          1468.92|               70.71|\n",
            "+------------+----+-----------+-----+-------+----------+----------+---------+-----------+--------+----------+---------+---+----------+-----------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- crop: string (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            " |-- season: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- area: double (nullable = true)\n",
            " |-- production: double (nullable = true)\n",
            " |-- fertilizer: double (nullable = true)\n",
            " |-- pesticide: double (nullable = true)\n",
            " |-- yield: double (nullable = true)\n",
            " |-- nitrogen: double (nullable = true)\n",
            " |-- phosphorus: double (nullable = true)\n",
            " |-- potassium: double (nullable = true)\n",
            " |-- ph: double (nullable = true)\n",
            " |-- avg_temp_c: double (nullable = true)\n",
            " |-- total_rainfall_mm: double (nullable = true)\n",
            " |-- avg_humidity_percent: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# ðŸ”¹ 10  1ï¸âƒ£Split Data\n",
        "train_data, test_data = df_spark.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "zl8xf2_-D0ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------\n",
        "# ðŸ”¹ 11ï¸âƒ£ Define Models\n",
        "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor, DecisionTreeRegressor\n",
        "\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(featuresCol=\"scaled_features\", labelCol=\"yield_log\"),\n",
        "    \"Random Forest\": RandomForestRegressor(featuresCol=\"scaled_features\", labelCol=\"yield_log\", numTrees=100),\n",
        "    \"GBT Regressor\": GBTRegressor(featuresCol=\"scaled_features\", labelCol=\"yield_log\", maxIter=50),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(featuresCol=\"scaled_features\", labelCol=\"yield_log\")\n",
        "}\n",
        "\n",
        "# ----------------------------\n",
        "# ðŸ”¹ 12ï¸âƒ£ Train, Predict, Evaluate\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "evaluator_rmse = RegressionEvaluator(labelCol=\"yield_log\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=\"yield_log\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    model_trained = model.fit(train_data)\n",
        "    predictions = model_trained.transform(test_data)\n",
        "\n",
        "    # Convert predictions back to original scale\n",
        "    predictions = predictions.withColumn(\"prediction_original\", expm1(\"prediction\"))\n",
        "\n",
        "    # Evaluate on log scale\n",
        "    rmse_log = evaluator_rmse.evaluate(predictions)\n",
        "    r2_log = evaluator_r2.evaluate(predictions)\n",
        "\n",
        "    # Evaluate on original scale\n",
        "    evaluator_rmse_orig = RegressionEvaluator(labelCol=\"yield\", predictionCol=\"prediction_original\", metricName=\"rmse\")\n",
        "    evaluator_r2_orig = RegressionEvaluator(labelCol=\"yield\", predictionCol=\"prediction_original\", metricName=\"r2\")\n",
        "    rmse_orig = evaluator_rmse_orig.evaluate(predictions)\n",
        "    r2_orig = evaluator_r2_orig.evaluate(predictions)\n",
        "\n",
        "    print(f\"RMSE (log scale): {rmse_log:.4f}, RÂ² (log scale): {r2_log:.4f}\")\n",
        "    print(f\"RMSE (original scale): {rmse_orig:.4f}, RÂ² (original scale): {r2_orig:.4f}\")\n",
        "\n",
        "    # Show sample predictions\n",
        "    predictions.select(\"yield\", \"prediction_original\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hCcDuUzD8lI",
        "outputId": "67c87a4e-3203-4021-cfa7-5aa9a3da30c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Linear Regression ---\n",
            "RMSE (log scale): 0.2824, RÂ² (log scale): 0.8861\n",
            "RMSE (original scale): 10.2053, RÂ² (original scale): -0.0558\n",
            "+-----------+-------------------+\n",
            "|      yield|prediction_original|\n",
            "+-----------+-------------------+\n",
            "|1.147857143| 1.1332131126154503|\n",
            "|0.784347826| 1.0860829119578823|\n",
            "|      6.232|  1.943350459923341|\n",
            "|       1.21| 1.6157019573615758|\n",
            "|0.957391304|  1.155544688296508|\n",
            "+-----------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "--- Random Forest ---\n",
            "RMSE (log scale): 0.1870, RÂ² (log scale): 0.9500\n",
            "RMSE (original scale): 3.2053, RÂ² (original scale): 0.8959\n",
            "+-----------+-------------------+\n",
            "|      yield|prediction_original|\n",
            "+-----------+-------------------+\n",
            "|1.147857143| 1.3008902807835683|\n",
            "|0.784347826| 0.8821243272408814|\n",
            "|      6.232|  6.141236681522768|\n",
            "|       1.21| 0.9922039648462673|\n",
            "|0.957391304| 0.9732589499624517|\n",
            "+-----------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "--- GBT Regressor ---\n",
            "RMSE (log scale): 0.0919, RÂ² (log scale): 0.9879\n",
            "RMSE (original scale): 1.3143, RÂ² (original scale): 0.9825\n",
            "+-----------+-------------------+\n",
            "|      yield|prediction_original|\n",
            "+-----------+-------------------+\n",
            "|1.147857143|  1.180873777776761|\n",
            "|0.784347826| 0.6700369897021978|\n",
            "|      6.232|  7.261576019907313|\n",
            "|       1.21|  1.275166893537606|\n",
            "|0.957391304| 0.9174126642635129|\n",
            "+-----------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "--- Decision Tree ---\n",
            "RMSE (log scale): 0.1076, RÂ² (log scale): 0.9834\n",
            "RMSE (original scale): 1.9997, RÂ² (original scale): 0.9595\n",
            "+-----------+-------------------+\n",
            "|      yield|prediction_original|\n",
            "+-----------+-------------------+\n",
            "|1.147857143| 1.2549460065991724|\n",
            "|0.784347826| 0.6712126377685024|\n",
            "|      6.232|  7.045073100051405|\n",
            "|       1.21| 1.0812985000761268|\n",
            "|0.957391304| 0.9344666999367636|\n",
            "+-----------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}